{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa984c75",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55e9bd",
   "metadata": {},
   "source": [
    "## 残差块（ResNet Block）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b158090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "#from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cadfd-62e7-4848-8e85-eb309aef73fa",
   "metadata": {},
   "source": [
    "### - 标准残差块（Identity Block）\n",
    "\n",
    "标准残差块是 ResNet 中常用的基本构建块，适用于输入激活值（记作 $a^{[l]}$）与输出激活值（记作 $a^{[l+2]}$）具有相同维度的情况。为了更好地解释 ResNet 的标准残差块发生的不同步骤，下面是一个展示每一步的替代图表：\n",
    "\n",
    "<img src=\"images/idblock2_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **图 3** </u><font color='purple'> ：**标准残差块。** 跳跃连接“跳过”了两层。</center></caption>\n",
    "\n",
    "上方路径是“快捷路径（shortcut path）”。下方路径是“主路径（main path）”。在这个图表中，我们明确标出了每一层中的 CONV2D 和 ReLU 步骤。为了加速训练，我们还添加了 BatchNorm 步骤。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/idblock3_kiank.png\" style=\"width:650px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **图 4** </u><font color='purple'> ：**标准残差块。** 跳跃连接“跳过”了三层。</center></caption>\n",
    "\n",
    "以下是具体的步骤：\n",
    "\n",
    "主路径的第一个组件：\n",
    "- 第一个 CONV2D 层有 $F_1$ 个过滤器，形状为 (1,1)，步幅为 (1,1)。其填充方式为 \"valid\"，名称应为 `conv_name_base + '2a'`。使用随机初始化时的种子值为 0。\n",
    "- 第一个 BatchNorm 层对通道轴进行归一化，其名称应为 `bn_name_base + '2a'`。\n",
    "- 然后应用 ReLU 激活函数。这一步无需名称和超参数。\n",
    "\n",
    "主路径的第二个组件：\n",
    "- 第二个 CONV2D 层有 $F_2$ 个过滤器，形状为 $(f,f)$，步幅为 (1,1)。其填充方式为 \"same\"，名称应为 `conv_name_base + '2b'`。使用随机初始化时的种子值为 0。\n",
    "- 第二个 BatchNorm 层对通道轴进行归一化，其名称应为 `bn_name_base + '2b'`。\n",
    "- 然后应用 ReLU 激活函数。这一步无需名称和超参数。\n",
    "\n",
    "主路径的第三个组件：\n",
    "- 第三个 CONV2D 层有 $F_3$ 个过滤器，形状为 (1,1)，步幅为 (1,1)。其填充方式为 \"valid\"，名称应为 `conv_name_base + '2c'`。使用随机初始化时的种子值为 0。\n",
    "- 第三个 BatchNorm 层对通道轴进行归一化，其名称应为 `bn_name_base + '2c'`。注意，此组件没有 ReLU 激活函数。\n",
    "\n",
    "最终步骤：\n",
    "- 将快捷路径和输入相加。\n",
    "- 然后应用 ReLU 激活函数。这一步无需名称和超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d2f26",
   "metadata": {},
   "source": [
    "- ResNet沿用了VGG全3x3卷积层的设计，残差块里首先有2个有相同输出通道数的3x3卷积层。每个卷积层后接一个批量归一化（Batch Norm）和ReLU激活函数。然后我们将输入跳过这2个卷积运算后直接加在最后的ReLU激活函数前。\n",
    "\n",
    "- 这样的设计要求2个卷积层的输出与输入形状一样，从而可以相加。如果想要改变通道数，就需要引入一个额外的1x1卷积层来将输入变换成需要的形状后再做相加运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c00c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1):\n",
    "        ####\n",
    "        #@param\n",
    "        # input_channels:输入通道数\n",
    "        # num_channels:  输出通道数\n",
    "        # use_1x1conv:   是否使用1x1卷积层\n",
    "        # strides:       步幅\n",
    "        ####\n",
    "        super().__init__()\n",
    "        #第一个3x3卷积，输入和输出的通道数相同，也支持通过选择不同的stride（步幅）来调整通道数。如果选择了调整通道数，1x1卷积层中也会做相同变换\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            input_channels, num_channels, kernel_size=3,\n",
    "                            padding=1, stride=strides)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        \n",
    "        if use_1x1conv:\n",
    "            #注意这里的“输入通道数”和“输出通道数”，输出通道数为num_channels从而和3x3卷积层的输出结果保持通道数相同 --> 从而能做相加运算\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        #Y += X\n",
    "        return F.relu(Y + X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e29da-ea3e-4bb6-8e3c-45349dae7547",
   "metadata": {},
   "source": [
    "输入和输出形状一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c3e87-499b-4785-9d8f-aff305082408",
   "metadata": {},
   "source": [
    "增加输出通道数的同时，减半输出的高和宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a98fafc-f9ff-418a-ae5f-a17006ff6186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3,3)\n",
    "X = torch.rand(4,3,6,6)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7e5b6e4-9589-4dc1-8f32-1ac33f14e833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3,6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46ba5e-a242-4334-a099-b344dff3fcd2",
   "metadata": {},
   "source": [
    "## ResNet模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed6ee1-bc6f-4206-84b4-b703f90b0a6b",
   "metadata": {},
   "source": [
    "![ResNet架构](images/ResNet_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8298c4c8-968c-4173-b416-bcd58b94f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#进入残差块之前的操作，和GoogleNet类似\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d5473-f1cb-4c04-8f83-caab5085a86d",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "**Q: '*'blk的含义**\n",
    "\n",
    "blk = [Residual1, Residual2, Residual3]\n",
    "nn.Sequential(*blk)\n",
    "\n",
    "--> 等价于\n",
    "\n",
    "nn.Sequential(Residual1, Residual2, Residual3)\n",
    "\n",
    "**Q: 为什么第一个block不需要1x1卷积？**\n",
    "1. 第一个block指的是从输入经过7x7卷积层（7x7 Conv）、批归一化(Batch Norm)和最大池化（3x3 Max Pooling）之后的第一个残差块（Residual Block）\n",
    "2. 第一个block是直接作用于网络的输入数据，通常不会改变特征图的通道数或空间尺寸，因此主路径和short cut的输出天然一致，不需要额外的调整操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0698e0f-71ef-4e49-a8e1-8454b51f2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n",
    "    if first_block:\n",
    "        assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_channels, out_channels))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9edb88-e760-463f-8364-9e053493ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add_module(\"resnet_block1\", resnet_block(64,64,2, first_block=True))\n",
    "net.add_module(\"resnet_block2\", resnet_block(64,128,2, first_block=True))\n",
    "net.add_module(\"resnet_block3\", resnet_block(128,256,2, first_block=True))\n",
    "net.add_module(\"resnet_block4\", resnet_block(256,512,2, first_block=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
